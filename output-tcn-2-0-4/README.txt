Using tcn dropout, 64 window size, used dilations=[1, 2, 4, 8, 16, 32, 64]
tcn-2-0.ipynb

Using TCN library:

input (14231, 64, 25)

TCN:
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_5 (InputLayer)         [(None, 64, 25)]          0         
_________________________________________________________________
tcn_8 (TCN)                  (None, 64, 32)            36288     
_________________________________________________________________
tcn_9 (TCN)                  (None, 16)                9552      
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 17        
=================================================================
Total params: 45,857
Trainable params: 45,857
Non-trainable params: 0
_________________________________________________________________
tcn_6 filters 32
tcn_7 filters 16
dropout on tcn layers 0,2
dilations [1, 2, 4, 8, 16, 32, 64]

epochs 100
batch 200
validation split 0,02
===============================
MAE: 13.392376899719238

R^2: 0.793411910533905

RMSE: 18.658845901489258
